{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d9473429",
            "metadata": {},
            "source": [
                "# Diabetic Retinopathy: Fast-Track Improvement (90%+ Goal)\n",
                "\n",
                "**Objective**: Maximize accuracy in < 4 hours.\n",
                "**Key Strategy**: \n",
                "1. **Physical Oversampling**: Explicitly duplicate minority classes (Severity 1, 3, 4).\n",
                "2. **OneCycleLR**: \"Super-convergence\" scheduler.\n",
                "3. **Model EMA**: Exponential Moving Average for weight stabilization.\n",
                "4. **Full Visualization**: CM, ROC, Grad-CAM included.\n",
                "\n",
                "**Instructions**:\n",
                "- Enable **Internet**.\n",
                "- Select **GPU T4 x2** or **P100**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cf4958d4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === IMPORTS & SETUP ===\n",
                "!pip install -q \"numpy<2.0\" timm==0.9.16 grad-cam scikit-learn scipy seaborn\n",
                "\n",
                "import os\n",
                "import cv2\n",
                "import time\n",
                "import random\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm.auto import tqdm\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix, classification_report\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torch.cuda.amp import autocast, GradScaler\n",
                "import torchvision.transforms as transforms\n",
                "\n",
                "import timm\n",
                "from timm.utils import ModelEmaV2\n",
                "\n",
                "from pytorch_grad_cam import GradCAM\n",
                "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
                "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
                "\n",
                "# Check Internet\n",
                "import socket\n",
                "try:\n",
                "    socket.create_connection((\"huggingface.co\", 443), timeout=5)\n",
                "    print(\"✓ Internet OK\")\n",
                "except:\n",
                "    print(\"❌ Internet OFF. Please enable it in Settings.\")\n",
                "\n",
                "# Seed\n",
                "def seed_everything(seed=42):\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "seed_everything(42)\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d56155f9",
            "metadata": {},
            "source": [
                "## 1. Aggressive Data Balancing & Loader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0a37035",
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = '/kaggle/input/aptos2019-blindness-detection'\n",
                "df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
                "df['path'] = df['id_code'].apply(lambda x: os.path.join(DATA_DIR, 'train_images', x + '.png'))\n",
                "df = df.rename(columns={'diagnosis': 'label'})\n",
                "\n",
                "# === OVERSAMPLING STRATEGY ===\n",
                "df_1 = df[df['label'] == 1]\n",
                "df_3 = df[df['label'] == 3]\n",
                "df_4 = df[df['label'] == 4]\n",
                "\n",
                "df_balanced = pd.concat([\n",
                "    df,                # Original data\n",
                "    df_3, df_3, df_3, df_3, # 4x copies of Class 3\n",
                "    df_4, df_4, df_4,       # 3x copies of Class 4\n",
                "    df_1, df_1              # 2x copies of Class 1\n",
                "]).reset_index(drop=True)\n",
                "\n",
                "print(\"Balanced Distribution:\")\n",
                "print(df_balanced['label'].value_counts().sort_index())\n",
                "\n",
                "# Image Loader (Ben Graham)\n",
                "def load_ben_color(path, sigmaX=10, target_size=256):\n",
                "    image = cv2.imread(path)\n",
                "    if image is None: return np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
                "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
                "    mask = gray > 7\n",
                "    if mask.sum() > 0:\n",
                "        rows = np.any(mask, axis=1)\n",
                "        cols = np.any(mask, axis=0)\n",
                "        rmin, rmax = np.where(rows)[0][[0, -1]]\n",
                "        cmin, cmax = np.where(cols)[0][[0, -1]]\n",
                "        image = image[rmin:rmax+1, cmin:cmax+1]\n",
                "    image = cv2.resize(image, (target_size, target_size))\n",
                "    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), sigmaX), -4, 128)\n",
                "    return image\n",
                "\n",
                "class DRDataset(Dataset):\n",
                "    def __init__(self, df, transform=None):\n",
                "        self.df = df\n",
                "        self.transform = transform\n",
                "    def __len__(self): return len(self.df)\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        img = load_ben_color(row['path'])\n",
                "        if self.transform: img = self.transform(img)\n",
                "        return img, torch.tensor(row['label'], dtype=torch.long)\n",
                "\n",
                "train_tf = transforms.Compose([\n",
                "    transforms.ToPILImage(),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomVerticalFlip(),\n",
                "    transforms.RandomRotation(30),\n",
                "    transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),\n",
                "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "val_tf = transforms.Compose([\n",
                "    transforms.ToPILImage(),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6477ea88",
            "metadata": {},
            "source": [
                "## 2. Model & Training Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dddae34b",
            "metadata": {},
            "outputs": [],
            "source": [
                "class CustomSwin(nn.Module):\n",
                "    def __init__(self, num_classes=5):\n",
                "        super().__init__()\n",
                "        self.backbone = timm.create_model('swinv2_base_window8_256.ms_in1k', pretrained=True, num_classes=0, img_size=256)\n",
                "        self.head = nn.Sequential(\n",
                "            nn.Dropout(0.5),\n",
                "            nn.Linear(self.backbone.num_features, 512),\n",
                "            nn.BatchNorm1d(512),\n",
                "            nn.GELU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(512, num_classes)\n",
                "        )\n",
                "    def forward(self, x):\n",
                "        return self.head(self.backbone(x))\n",
                "\n",
                "class FocalLoss(nn.Module):\n",
                "    def __init__(self, alpha=0.9, gamma=2):\n",
                "        super().__init__()\n",
                "        self.alpha = alpha\n",
                "        self.gamma = gamma\n",
                "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
                "    def forward(self, x, target):\n",
                "        logpt = -self.ce(x, target)\n",
                "        pt = torch.exp(logpt)\n",
                "        return -(self.alpha * (1-pt)**self.gamma * logpt).mean()\n",
                "\n",
                "def train_one_epoch(model, ema, loader, opt, sched, crit, scaler):\n",
                "    model.train()\n",
                "    avg_loss = 0\n",
                "    for img, label in tqdm(loader, leave=False):\n",
                "        img, label = img.to(device), label.to(device)\n",
                "        opt.zero_grad()\n",
                "        with autocast():\n",
                "            out = model(img)\n",
                "            loss = crit(out, label)\n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.step(opt)\n",
                "        scaler.update()\n",
                "        sched.step()\n",
                "        ema.update(model)\n",
                "        avg_loss += loss.item()\n",
                "    return avg_loss / len(loader)\n",
                "\n",
                "def validate(model, loader):\n",
                "    model.eval()\n",
                "    preds, targets, probs = [], [], []\n",
                "    with torch.no_grad():\n",
                "        for img, label in loader:\n",
                "            img = img.to(device)\n",
                "            out1 = model(img)\n",
                "            out2 = model(torch.flip(img, [3]))\n",
                "            out = (out1 + out2) / 2\n",
                "            prob = torch.softmax(out, dim=1)\n",
                "            probs.extend(prob.cpu().numpy())\n",
                "            preds.extend(out.argmax(1).cpu().numpy())\n",
                "            targets.extend(label.numpy())\n",
                "    return accuracy_score(targets, preds), cohen_kappa_score(targets, preds, weights='quadratic'), np.array(probs), np.array(targets)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7685778e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CONFIG ===\n",
                "FOLDS = 5\n",
                "EPOCHS = 15\n",
                "BATCH = 16\n",
                "LR = 1e-4\n",
                "\n",
                "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
                "oof_probs = []\n",
                "oof_targets = []\n",
                "\n",
                "print(\"Starting Improvement Run...\\n\")\n",
                "\n",
                "for fold, (train_idx, val_idx) in enumerate(skf.split(df_balanced['path'], df_balanced['label'])):\n",
                "    print(f\"\\n{'='*20} FOLD {fold+1}/{FOLDS} {'='*20}\")\n",
                "    \n",
                "    train_ds = DRDataset(df_balanced.iloc[train_idx], train_tf)\n",
                "    val_ds = DRDataset(df_balanced.iloc[val_idx], val_tf)\n",
                "    \n",
                "    train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
                "    val_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False, num_workers=4)\n",
                "    \n",
                "    model = CustomSwin().to(device)\n",
                "    ema = ModelEmaV2(model, decay=0.999)\n",
                "    opt = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
                "    sched = optim.lr_scheduler.OneCycleLR(opt, max_lr=LR, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
                "    crit = FocalLoss()\n",
                "    scaler = GradScaler()\n",
                "    \n",
                "    best_acc = 0\n",
                "    best_probs = None\n",
                "    best_targets = None\n",
                "    \n",
                "    for epoch in range(EPOCHS):\n",
                "        loss = train_one_epoch(model, ema, train_loader, opt, sched, crit, scaler)\n",
                "        acc, kappa, probs, targets = validate(ema.module, val_loader)\n",
                "        \n",
                "        print(f\"Epoch {epoch+1} | Loss: {loss:.4f} | EMA Acc: {acc:.4f} | Kappa: {kappa:.4f}\", end=\"\")\n",
                "        \n",
                "        if acc > best_acc:\n",
                "            best_acc = acc\n",
                "            best_probs = probs\n",
                "            best_targets = targets\n",
                "            torch.save(ema.module.state_dict(), f'fold_{fold+1}_best_ema.pth')\n",
                "            print(\" [Saved]\")\n",
                "        else:\n",
                "            print()\n",
                "            \n",
                "    # Store OOF predictions\n",
                "    oof_probs.append(best_probs)\n",
                "    oof_targets.append(best_targets)\n",
                "            \n",
                "    del model, ema, opt, sched, scaler\n",
                "    torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "57ac0708",
            "metadata": {},
            "source": [
                "## 3. Visualization & Ensembling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "272ec383",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === ENSEMBLING RESULTS ===\n",
                "all_probs = np.concatenate(oof_probs)\n",
                "all_targets = np.concatenate(oof_targets)\n",
                "all_preds = np.argmax(all_probs, axis=1)\n",
                "\n",
                "final_acc = accuracy_score(all_targets, all_preds)\n",
                "final_kappa = cohen_kappa_score(all_targets, all_preds, weights='quadratic')\n",
                "\n",
                "print(\"\\n\" + \"=\"*40)\n",
                "print(f\"FINAL ENSEMBLE RESULTS\")\n",
                "print(f\"Accuracy: {final_acc:.4f}\")\n",
                "print(f\"Kappa:    {final_kappa:.4f}\")\n",
                "print(\"=\"*40)\n",
                "\n",
                "# === CONFUSION MATRIX ===\n",
                "cm = confusion_matrix(all_targets, all_preds)\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
                "plt.title(f'Confusion Matrix (Kappa: {final_kappa:.4f})', fontsize=14)\n",
                "plt.ylabel('True Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.savefig('confusion_matrix_final.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "942690fc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === GRAD-CAM VISUALIZATION ===\n",
                "# Visualize the LAST fold model for demonstration\n",
                "model = CustomSwin(num_classes=5).to(device)\n",
                "model.load_state_dict(torch.load(f'fold_{FOLDS}_best_ema.pth'))\n",
                "model.eval()\n",
                "\n",
                "target_layers = [model.backbone.layers[-1].blocks[-1].norm1]\n",
                "cam = GradCAM(model=model, target_layers=target_layers)\n",
                "\n",
                "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "# Pick some random samples from class 3 and 4 (severe)\n",
                "samples = df_balanced[df_balanced['label'].isin([3, 4])].sample(8)\n",
                "\n",
                "for idx, (_, row) in enumerate(samples.iterrows()):\n",
                "    img = load_ben_color(row['path'])\n",
                "    input_tensor = val_tf(img).unsqueeze(0).to(device)\n",
                "    rgb_img = img.astype(np.float32) / 255.0\n",
                "    \n",
                "    target_category = int(row['label'])\n",
                "    with torch.no_grad():\n",
                "        out = model(input_tensor)\n",
                "        pred = out.argmax(1).item()\n",
                "        \n",
                "    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(target_category)])[0]\n",
                "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
                "    \n",
                "    axes[idx].imshow(visualization)\n",
                "    axes[idx].set_title(f\"True: {target_category} | Pred: {pred}\", \n",
                "                        color='green' if target_category==pred else 'red', fontweight='bold')\n",
                "    axes[idx].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('gradcam_final.png')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
